{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf16eb289ca84e1998c79781f96a8cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55a3233e8aa243d69ff8b6a6bef11828",
              "IPY_MODEL_edbe27b84d334f82ad86a7ec61e5ac9e",
              "IPY_MODEL_167310e124f143a4bb22718cc99a7451"
            ],
            "layout": "IPY_MODEL_6ca8eecc26b546c0b5a6678f12f960a7"
          }
        },
        "55a3233e8aa243d69ff8b6a6bef11828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65c9ce9cd9614d08b437c05452481668",
            "placeholder": "​",
            "style": "IPY_MODEL_509d52ddc5fb41468cacb0a79fa5a47c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "edbe27b84d334f82ad86a7ec61e5ac9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cb314989828423099c8ae5785427051",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8561ebf8186d46748c88561df116f0c5",
            "value": 2
          }
        },
        "167310e124f143a4bb22718cc99a7451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89f8d99a6b67425e9d76f40dc2fc982f",
            "placeholder": "​",
            "style": "IPY_MODEL_1df8e3fc4503421db446dd6ffbfe7fa4",
            "value": " 2/2 [01:06&lt;00:00, 30.54s/it]"
          }
        },
        "6ca8eecc26b546c0b5a6678f12f960a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65c9ce9cd9614d08b437c05452481668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "509d52ddc5fb41468cacb0a79fa5a47c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cb314989828423099c8ae5785427051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8561ebf8186d46748c88561df116f0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89f8d99a6b67425e9d76f40dc2fc982f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1df8e3fc4503421db446dd6ffbfe7fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune Llama 2 in Google Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "OSHlAbqzDFDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate==0.21.0 bitsandbytes==0.40.2 transformers==4.31.0 xformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q40BkHC9sr1P",
        "outputId": "f64c3d22-86de-4728-ba20-559a946a14a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "EWW3TglVtFko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_to_text = pipeline(\n",
        "   \"image-to-text\",\n",
        "   model=\"nlpconnect/vit-gpt2-image-captioning\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Funcion para tranforma una image a texto\n",
        "# la idea es pasar la imagen a texto\n",
        "# y junto con el texto de la noticia\n",
        "# pasarla como input al LLM para obtener una\n",
        "# respuesta en lenguaje natural\n",
        "def get_image_description(image_url):\n",
        "    i_image = Image.open(image_url)\n",
        "    if i_image.mode != \"RGB\":\n",
        "      i_image = i_image.convert(mode=\"RGB\")\n",
        "\n",
        "    # Ojo el modelo recibe un Image de PIL\n",
        "    # con los datos que se cargan con streamlit\n",
        "    # hay que crear este input, pero debe\n",
        "    # funcionar igual que el modelo para clasificar las imagenes\n",
        "    r = image_to_text(i_image)[0]\n",
        "    return r['generated_text']"
      ],
      "metadata": {
        "id": "Tm_4E1Lf-zUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codigo para cargar el LLM (LLama 2)\n",
        "\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=getattr(torch, 'float16'),\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")\n",
        "\n",
        "model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# Load base model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map= {\"\": 0}\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "# Load LLaMA tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens= 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50,
          "referenced_widgets": [
            "cf16eb289ca84e1998c79781f96a8cee",
            "55a3233e8aa243d69ff8b6a6bef11828",
            "edbe27b84d334f82ad86a7ec61e5ac9e",
            "167310e124f143a4bb22718cc99a7451",
            "6ca8eecc26b546c0b5a6678f12f960a7",
            "65c9ce9cd9614d08b437c05452481668",
            "509d52ddc5fb41468cacb0a79fa5a47c",
            "4cb314989828423099c8ae5785427051",
            "8561ebf8186d46748c88561df116f0c5",
            "89f8d99a6b67425e9d76f40dc2fc982f",
            "1df8e3fc4503421db446dd6ffbfe7fa4"
          ]
        },
        "id": "jHlVlHZItAWN",
        "outputId": "e0232f17-e1a2-4d43-e2cd-6d25a7aaec58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf16eb289ca84e1998c79781f96a8cee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcion para crear la respuesta en lenguaje natural\n",
        "\n",
        "prompt_base = \"\"\"Give a natural language response of the results \\\n",
        "and try to explain to me with a lot of details the reason for the classification. \\n\\n\"\"\"\n",
        "\n",
        "def nlp_answer(p: int, text = None, image = None):\n",
        "  assert text or image, \"Text or/and Image are requiered\"\n",
        "\n",
        "  prompt = prompt_base\n",
        "\n",
        "  if text:\n",
        "    prompt += f\"News' Text: {text}\\n\"\n",
        "  if image:\n",
        "    prompt += f\"News' Image Description: {image}\\n\"\n",
        "\n",
        "\n",
        "  if p > 70:\n",
        "    final_prompt = f'The news is fake with a {p}% probability, beacuse'\n",
        "  elif p < 30:\n",
        "    final_prompt = f'The news is real with a {100-p}% probability, beacuse'\n",
        "  else:\n",
        "    final_prompt = 'There is not much certainty about the classification of the news item, beacuse'\n",
        "\n",
        "  prompt += 'Result and Explanation: ' + final_prompt\n",
        "\n",
        "\n",
        "  r = pipe(prompt, return_full_text=False, temperature=0.8)\n",
        "  result = final_prompt + r[0]['generated_text']\n",
        "  result = result.split('\\n')[0]\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "mFQU3NMV4WDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplos"
      ],
      "metadata": {
        "id": "aCeO-eyvAWg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'rainbow faucet selftitled.'\n",
        "image = 'a candle is lit in a car window.'"
      ],
      "metadata": {
        "id": "_9X8djhg8Mwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp_answer(80, text, image))\n",
        "print()\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNNRpJV68ZpA",
        "outputId": "c04f08b9-0a6e-4abf-e10e-2984306a0517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The news is fake with a 80% probability, beacuse the text and image do not match. The text is about a rainbow faucet, but the image shows a candle being lit in a car window. This is a common technique used by fake news creators to make their content appear more believable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp_answer(50, text, image))\n",
        "print()\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdJ0Hyti9pGc",
        "outputId": "2f6bc809-ee49-42ac-d9f5-ae2d55aeb524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is not much certainty about the classification of the news item, beacuse the text and image do not provide any clear indication of the topic. The text could be about a new product, a creative expression, or a metaphor. The image could be a representation of a car ride, a candle, or a window. Therefore, the classification is \"Undetermined\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp_answer(10, image, image))\n",
        "print()\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuTcrKGa9rlS",
        "outputId": "950cd34f-00ef-4345-b6a4-7395d41e6446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The news is real with a 90% probability, beacuse the image description is very detailed and the image is clear.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dWzZbx_g8X3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bvav9TUh8X0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vkmdGK9l8Xxw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u0l_T6Jz8Xuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xgNe73SB8XrO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y5IfMSQQ8XiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zLMZ9xWB8XW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens= 200)"
      ],
      "metadata": {
        "id": "dnf96fRl1m7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"I want to label each token in the following sentences with the three classic labels of the named entity recognition task (Outer (O), Inside (I), Begin (B)). I want to tag skills for the labor market from job offers and job resumes\n",
        "\n",
        "Sentence: • Collaborate with Tech partners to design and deploy Machine Learning services that can be integrated with strategic systems .\n",
        "Labels: ['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] [END]\n",
        "\n",
        "Sentence: The role will be in the firm's Applied AI and Machine Learning organization and will involve working closely with Digital & Platform Services Operations .\n",
        "Labels:  \"\"\"\n",
        "\n",
        "len(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvz3reE31zOG",
        "outputId": "35ba818b-b792-475e-8a6b-ed2871d70429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "660"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = pipe(prompt, return_full_text=False, stop_sequence = \"[END]\")\n",
        "print(r[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZJm9TKy3SCX",
        "outputId": "7f2e3fdb-b462-456e-9e5f-cbaf646e68e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] [\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Give a natural language response of the results and try to explain to me with a lot of details the reason for the classification.\n",
        "\n",
        "## News' Description:\n",
        "Title: rainbow faucet selftitled.\n",
        "News' Image Description: a candle is lit in a car window.\n",
        "\n",
        "## Answer:\n",
        "The news is not a 50% fake news because\"\"\""
      ],
      "metadata": {
        "id": "M8PMIcZz6kZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = pipe(prompt, return_full_text=False, temperature=0.8)\n",
        "print(r[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERnwt4Qz6oMz",
        "outputId": "e8defcd3-a5a6-46ff-d22b-762bf2c3c92c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the image is not a real image of a rainbow faucet. The image is actually a stock photo of a candle lit in a car window. The image is not a real news article and is not a factual report of any kind. Therefore, it is a 100% fake news article.\n",
            "\n",
            "## Reason: \n",
            "The image is not a real image of a rainbow faucet, as there is no such thing as a faucet that produces rainbows. The image is actually a stock photo of a candle lit in a car window, which is a common image used in various contexts such as advertising, social media, and news articles. The image is not a real news article and is not a factual report of any kind. Therefore, it is a 100% fake news article.\n"
          ]
        }
      ]
    }
  ]
}