{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "def file_check(x):\n",
    "    try:\n",
    "        img = Image.open(f'images/{x}.jpg')\n",
    "        return img.mode\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "df = pd.read_csv('dataset_curso.csv')\n",
    "df['has_image'] = df['id'].apply(file_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>image_url</th>\n",
       "      <th>linked_submission_id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_image</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>16586</td>\n",
       "      <td>16586</td>\n",
       "      <td>16586</td>\n",
       "      <td>16451</td>\n",
       "      <td>14564</td>\n",
       "      <td>2022</td>\n",
       "      <td>16586</td>\n",
       "      <td>2022</td>\n",
       "      <td>16586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMYK</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>2699</td>\n",
       "      <td>2699</td>\n",
       "      <td>2699</td>\n",
       "      <td>2699</td>\n",
       "      <td>96</td>\n",
       "      <td>2603</td>\n",
       "      <td>2699</td>\n",
       "      <td>2603</td>\n",
       "      <td>2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RGB</th>\n",
       "      <td>37073</td>\n",
       "      <td>37073</td>\n",
       "      <td>37073</td>\n",
       "      <td>37073</td>\n",
       "      <td>2099</td>\n",
       "      <td>34974</td>\n",
       "      <td>37073</td>\n",
       "      <td>34974</td>\n",
       "      <td>37073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RGBA</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           clean_title  created_utc     id  image_url  linked_submission_id  \\\n",
       "has_image                                                                     \n",
       "False            16586        16586  16586      16451                 14564   \n",
       "CMYK                 1            1      1          1                     1   \n",
       "L                   32           32     32         32                    10   \n",
       "P                 2699         2699   2699       2699                    96   \n",
       "RGB              37073        37073  37073      37073                  2099   \n",
       "RGBA                 9            9      9          9                     9   \n",
       "\n",
       "           num_comments  score  upvote_ratio  2_way_label  \n",
       "has_image                                                  \n",
       "False              2022  16586          2022        16586  \n",
       "CMYK                  0      1             0            1  \n",
       "L                    22     32            22           32  \n",
       "P                  2603   2699          2603         2699  \n",
       "RGB               34974  37073         34974        37073  \n",
       "RGBA                  0      9             0            9  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('has_image').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g_/0lqz2qlx7cx96d901w35swh40000gn/T/ipykernel_93297/4196223939.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  image_dataset['image'] = image_dataset['id'].apply(lambda x: f'images/{x}.jpg')\n",
      "/var/folders/g_/0lqz2qlx7cx96d901w35swh40000gn/T/ipykernel_93297/4196223939.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  image_dataset['labels'] = image_dataset['2_way_label']\n"
     ]
    }
   ],
   "source": [
    "image_dataset = df[df['has_image'] == 'RGB']\n",
    "\n",
    "image_dataset['image'] = image_dataset['id'].apply(lambda x: f'images/{x}.jpg')\n",
    "image_dataset['labels'] = image_dataset['2_way_label']\n",
    "df = image_dataset[['clean_title', 'image', 'labels']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "image_to_text = pipeline(\n",
    "   \"image-to-text\", \n",
    "   model=\"nlpconnect/vit-gpt2-image-captioning\"\n",
    ")\n",
    "\n",
    "def get_image_description(image_url):\n",
    "    i_image = Image.open(image_url)\n",
    "    if i_image.mode != \"RGB\":\n",
    "      i_image = i_image.convert(mode=\"RGB\")\n",
    "\n",
    "    r = image_to_text(i_image)[0]\n",
    "    return r['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.sample(1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give a natural language response of the results and try to explain to me with a lot of details the reason for the classification. \n",
      "\n",
      "## News' Description: \n",
      "Title: rainbow faucet selftitled\n",
      "News' Image Description: a candle is lit in a car window \n",
      "\n",
      "## Answer: \n",
      "The news is not a 50% fake news because \n"
     ]
    }
   ],
   "source": [
    "news_title = x[0]\n",
    "image_description = get_image_description(x[1])\n",
    "\n",
    "prompt = \"\"\"I need you to help me to give an answer to \\\n",
    "the user of the user of the fake news detection system. \\\n",
    "Give a natural language response of the results \\\n",
    "and try to explain to the user reason for the classification. \\\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"Classify the next news in fake or not and explain me your selection.\\n\\n\"\"\"\n",
    "prompt = \"\"\"Give a natural language response of the results \\\n",
    "and try to explain to me with a lot of details the reason for the classification. \\n\\n\"\"\"\n",
    "\n",
    "prompt += \"## News' Description: \\n\"\n",
    "prompt += f\"Title: {news_title}\\n\"\n",
    "prompt += f\"News' Image Description: {image_description}\\n\\n\"\n",
    "\n",
    "# prompt += '## Result of the Classification:\\n\\n'\n",
    "# prompt += f\"Text Classification Model's Result: 50% of being fake news\\n\\n\"\n",
    "# prompt += f\"Image Classification Model's Result: 50% of being fake news\\n\\n\"\n",
    "\n",
    "prompt += \"## Answer: \\n\"\n",
    "prompt += \"The news is not a 50% fake news because \"\n",
    "\n",
    "print(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303e28ef4a48433d8342a43905a32569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abb9d7cd53c47499c2884c1cacd5ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121ca1ed7bc54e90a901eddc8fc20894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aeddb69d9884fc7929adb5467b3f9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/2.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576d9f7f5be34be4bb8bb759f7974cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510960d6c6a646b5a723f5418018312c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text2text_generator = pipeline(\"text2text-generation\",  model='declare-lab/flan-alpaca-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results indicate that the news is not a 50% fake news because the news is based on a variety of sources, such as a news website, news articles, and other sources.\n"
     ]
    }
   ],
   "source": [
    "r = text2text_generator(prompt, max_length = 1000)\n",
    "print(r[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"I want to label each token in the following sentences with the three classic labels of the named entity recognition task (Outer (O), Inside (I), Begin (B)). I want to tag skills for the labor market from job offers and job resumes\n",
    "\n",
    "\n",
    "Sentence: • Collaborate with Tech partners to design and deploy Machine Learning services that can be integrated with strategic systems .\n",
    "Labels: ['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "\n",
    "Sentence: The role will be in the firm's Applied AI and Machine Learning organization and will involve working closely with Digital & Platform Services Operations .\n",
    "Labels:  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      " \n",
      " \n",
      "t\n",
      " \n",
      " \n",
      "I want to label each token in the following sentences with the three classic labels of the named entity recognition task (Outer (O), Inside (I), Begin (B)). I want to tag skills for the labor market from job offers and job resumes\n",
      "\n",
      "\n",
      "Sentence: • Collaborate with Tech partners to design and deploy Machine Learning services that can be integrated with strategic systems .\n",
      "Labels: ['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Sentence: The role will be in the firm's Applied AI and Machine Learning organization and will involve working closely with Digital & Platform Services Operations .\n",
      "Labels:   ['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Sentence: • Collaborate with Tech partners to design and deploy Machine Learning services that can be integrated with strategic systems .\n",
      "Labels: ['O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/bigscience/bloom\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\twhile True:\n",
    "\t\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\t\ttext = response.json()[0]['generated_text']\n",
    "\t\tif text.strip()[-1] == ']':\n",
    "\t\t\tbreak\n",
    "\t\tprint(text.strip()[-20])\n",
    "\t\tpayload = {'inputs': text}\n",
    "\treturn text\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": prompt,\n",
    "})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Model google/flan-t5-xxl is currently loading', 'estimated_time': 1802.7086181640625}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/dany/src/school/uc/fake_news/model_response.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \t\tpayload \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39minputs\u001b[39m\u001b[39m'\u001b[39m: text}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \t\u001b[39mreturn\u001b[39;00m text\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m output \u001b[39m=\u001b[39m query({\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \t\u001b[39m\"\u001b[39;49m\u001b[39minputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \t\u001b[39m\"\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m100000\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X31sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m })\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X31sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(output)\n",
      "\u001b[1;32m/Users/dany/src/school/uc/fake_news/model_response.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mpost(API_URL, headers\u001b[39m=\u001b[39mheaders, json\u001b[39m=\u001b[39mpayload)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(response\u001b[39m.\u001b[39mjson())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m text \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39;49mjson()[\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mgenerated_text\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mif\u001b[39;00m text\u001b[39m.\u001b[39mstrip()[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X31sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \t\u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/google/flan-t5-xxl\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\twhile True:\n",
    "\t\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\t\tprint(response.json())\n",
    "\t\ttext = response.json()[0]['generated_text']\n",
    "\t\tif text.strip()[-1] == ']':\n",
    "\t\t\tbreak\n",
    "\t\tprint(text.strip()[-20])\n",
    "\t\tpayload = {'inputs': text}\n",
    "\treturn text\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": prompt,\n",
    "\t\"max_length\": 100000\n",
    "\n",
    "})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b327fdb7d82d41e3b0e2bc700513f82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd534bc1240451d94f564fef8a2d5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00005.safetensors:   0%|          | 0.00/9.60G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a51172e60c40ff99ebf3976615080a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00005.safetensors:   0%|          | 0.00/9.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 9999.71 MB. The target location /Users/dany/.cache/huggingface/hub only has 967.71 MB free disk space.\n",
      "  warnings.warn(\n",
      "/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 9999.71 MB. The target location /Users/dany/.cache/huggingface/hub/models--google--flan-t5-xxl/blobs only has 967.71 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54acd47f88984500a393da8c58ef7876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00005.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa940247dc5433f92274780d3ab6fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 9989.36 MB. The target location /Users/dany/.cache/huggingface/hub only has 89.11 MB free disk space.\n",
      "  warnings.warn(\n",
      "/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 9989.36 MB. The target location /Users/dany/.cache/huggingface/hub/models--google--flan-t5-xxl/blobs only has 89.11 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8309156a67214f03b1a9b3bff7b8940c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)el-00001-of-00005.h5:   0%|          | 0.00/9.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8975d1cf705f40eb828cf115e37c9c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 9999.71 MB. The target location /Users/dany/.cache/huggingface/hub only has 89.08 MB free disk space.\n",
      "  warnings.warn(\n",
      "/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 9999.71 MB. The target location /Users/dany/.cache/huggingface/hub/models--google--flan-t5-xxl/blobs only has 89.08 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d363b337804d7fad47ac8b6f590718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00005.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a2583ba56e46b1b7155315d7c63047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 9989.36 MB. The target location /Users/dany/.cache/huggingface/hub only has 89.55 MB free disk space.\n",
      "  warnings.warn(\n",
      "/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 9989.36 MB. The target location /Users/dany/.cache/huggingface/hub/models--google--flan-t5-xxl/blobs only has 89.55 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590bac732ddb4d9fb98048199726a0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)el-00001-of-00005.h5:   0%|          | 0.00/9.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model google/flan-t5-xxl with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSeq2SeqLM'>, <class 'transformers.models.t5.modeling_t5.T5ForConditionalGeneration'>, <class 'transformers.models.t5.modeling_tf_t5.TFT5ForConditionalGeneration'>). See the original errors:\n\nwhile loading with AutoModelForSeq2SeqLM, an error is thrown:\nTraceback (most recent call last):\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 3128, in from_pretrained\n    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 1052, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n                      ^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 430, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1431, in hf_hub_download\n    http_get(\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 554, in http_get\n    temp_file.write(chunk)\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 483, in func_wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nOSError: [Errno 28] No space left on device\n\nwhile loading with TFAutoModelForSeq2SeqLM, an error is thrown:\nTraceback (most recent call last):\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 2859, in from_pretrained\n    resolved_archive_file, _ = get_checkpoint_shard_files(\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 1052, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n                      ^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 430, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1431, in hf_hub_download\n    http_get(\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 554, in http_get\n    temp_file.write(chunk)\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 483, in func_wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nOSError: [Errno 28] No space left on device\n\nwhile loading with T5ForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 3128, in from_pretrained\n    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 1052, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n                      ^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 430, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1431, in hf_hub_download\n    http_get(\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 554, in http_get\n    temp_file.write(chunk)\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 483, in func_wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nOSError: [Errno 28] No space left on device\n\nwhile loading with TFT5ForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 2859, in from_pretrained\n    resolved_archive_file, _ = get_checkpoint_shard_files(\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 1052, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n                      ^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 430, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1431, in hf_hub_download\n    http_get(\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 554, in http_get\n    temp_file.write(chunk)\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 483, in func_wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nOSError: [Errno 28] No space left on device\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/dany/src/school/uc/fake_news/model_response.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dany/src/school/uc/fake_news/model_response.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m text2text_generator \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39;49m\u001b[39mtext2text-generation\u001b[39;49m\u001b[39m\"\u001b[39;49m,  model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgoogle/flan-t5-xxl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/pipelines/__init__.py:870\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m--> 870\u001b[0m     framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[1;32m    871\u001b[0m         model,\n\u001b[1;32m    872\u001b[0m         model_classes\u001b[39m=\u001b[39;49mmodel_classes,\n\u001b[1;32m    873\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    874\u001b[0m         framework\u001b[39m=\u001b[39;49mframework,\n\u001b[1;32m    875\u001b[0m         task\u001b[39m=\u001b[39;49mtask,\n\u001b[1;32m    876\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs,\n\u001b[1;32m    877\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    878\u001b[0m     )\n\u001b[1;32m    880\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    881\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/pipelines/base.py:282\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[39mfor\u001b[39;00m class_name, trace \u001b[39min\u001b[39;00m all_traceback\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    281\u001b[0m             error \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhile loading with \u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m, an error is thrown:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mtrace\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 282\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not load model \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m with any of the following classes: \u001b[39m\u001b[39m{\u001b[39;00mclass_tuple\u001b[39m}\u001b[39;00m\u001b[39m. See the original errors:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         )\n\u001b[1;32m    286\u001b[0m \u001b[39mif\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     framework \u001b[39m=\u001b[39m infer_framework(model\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not load model google/flan-t5-xxl with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSeq2SeqLM'>, <class 'transformers.models.t5.modeling_t5.T5ForConditionalGeneration'>, <class 'transformers.models.t5.modeling_tf_t5.TFT5ForConditionalGeneration'>). See the original errors:\n\nwhile loading with AutoModelForSeq2SeqLM, an error is thrown:\nTraceback (most recent call last):\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 3128, in from_pretrained\n    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 1052, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n                      ^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 430, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1431, in hf_hub_download\n    http_get(\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 554, in http_get\n    temp_file.write(chunk)\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 483, in func_wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nOSError: [Errno 28] No space left on device\n\nwhile loading with TFAutoModelForSeq2SeqLM, an error is thrown:\nTraceback (most recent call last):\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 2859, in from_pretrained\n    resolved_archive_file, _ = get_checkpoint_shard_files(\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 1052, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n                      ^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 430, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1431, in hf_hub_download\n    http_get(\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 554, in http_get\n    temp_file.write(chunk)\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 483, in func_wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nOSError: [Errno 28] No space left on device\n\nwhile loading with T5ForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 3128, in from_pretrained\n    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 1052, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n                      ^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 430, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1431, in hf_hub_download\n    http_get(\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 554, in http_get\n    temp_file.write(chunk)\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 483, in func_wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nOSError: [Errno 28] No space left on device\n\nwhile loading with TFT5ForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 2859, in from_pretrained\n    resolved_archive_file, _ = get_checkpoint_shard_files(\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 1052, in get_checkpoint_shard_files\n    cached_filename = cached_file(\n                      ^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/transformers/utils/hub.py\", line 430, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1431, in hf_hub_download\n    http_get(\n  File \"/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 554, in http_get\n    temp_file.write(chunk)\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 483, in func_wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nOSError: [Errno 28] No space left on device\n\n\n"
     ]
    }
   ],
   "source": [
    "text2text_generator = pipeline(\"text2text-generation\",  model='google/flan-t5-xxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake_news-6ZUGHfY-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
