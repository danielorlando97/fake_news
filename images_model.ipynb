{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/huggingface/transformers/issues/17971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "def file_check(x):\n",
    "    try:\n",
    "        img = Image.open(f'images/{x}.jpg')\n",
    "        return img.mode\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "df = pd.read_csv('dataset_curso.csv')\n",
    "df['has_image'] = df['id'].apply(file_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>image_url</th>\n",
       "      <th>linked_submission_id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_image</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>16586</td>\n",
       "      <td>16586</td>\n",
       "      <td>16586</td>\n",
       "      <td>16451</td>\n",
       "      <td>14564</td>\n",
       "      <td>2022</td>\n",
       "      <td>16586</td>\n",
       "      <td>2022</td>\n",
       "      <td>16586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMYK</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>2699</td>\n",
       "      <td>2699</td>\n",
       "      <td>2699</td>\n",
       "      <td>2699</td>\n",
       "      <td>96</td>\n",
       "      <td>2603</td>\n",
       "      <td>2699</td>\n",
       "      <td>2603</td>\n",
       "      <td>2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RGB</th>\n",
       "      <td>37073</td>\n",
       "      <td>37073</td>\n",
       "      <td>37073</td>\n",
       "      <td>37073</td>\n",
       "      <td>2099</td>\n",
       "      <td>34974</td>\n",
       "      <td>37073</td>\n",
       "      <td>34974</td>\n",
       "      <td>37073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RGBA</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           clean_title  created_utc     id  image_url  linked_submission_id  \\\n",
       "has_image                                                                     \n",
       "False            16586        16586  16586      16451                 14564   \n",
       "CMYK                 1            1      1          1                     1   \n",
       "L                   32           32     32         32                    10   \n",
       "P                 2699         2699   2699       2699                    96   \n",
       "RGB              37073        37073  37073      37073                  2099   \n",
       "RGBA                 9            9      9          9                     9   \n",
       "\n",
       "           num_comments  score  upvote_ratio  2_way_label  \n",
       "has_image                                                  \n",
       "False              2022  16586          2022        16586  \n",
       "CMYK                  0      1             0            1  \n",
       "L                    22     32            22           32  \n",
       "P                  2603   2699          2603         2699  \n",
       "RGB               34974  37073         34974        37073  \n",
       "RGBA                  0      9             0            9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('has_image').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g_/0lqz2qlx7cx96d901w35swh40000gn/T/ipykernel_55878/1001678944.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  image_dataset['image'] = image_dataset['id'].apply(lambda x: f'images/{x}.jpg')\n",
      "/var/folders/g_/0lqz2qlx7cx96d901w35swh40000gn/T/ipykernel_55878/1001678944.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  image_dataset['labels'] = image_dataset['2_way_label']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37073.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.552531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             labels\n",
       "count  37073.000000\n",
       "mean       0.552531\n",
       "std        0.497239\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image_dataset = df[df['has_image'] == 'RGB']\n",
    "\n",
    "image_dataset['image'] = image_dataset['id'].apply(lambda x: f'images/{x}.jpg')\n",
    "image_dataset['labels'] = image_dataset['2_way_label']\n",
    "df = image_dataset[['image', 'labels']]\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                 37073\n",
       "unique                37073\n",
       "top       images/239vnh.jpg\n",
       "freq                      1\n",
       "Name: image, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dany/.local/share/virtualenvs/fake_news-6ZUGHfY-/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'labels', '__index_level_0__'],\n",
       "        num_rows: 29658\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'labels', '__index_level_0__'],\n",
       "        num_rows: 7415\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, Image\n",
    "\n",
    "image_dataset = Dataset.from_pandas(df) \\\n",
    "    .cast_column('image', Image()) \\\n",
    "    .train_test_split(test_size=0.2)\n",
    "image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "model_id = \"google/vit-base-patch16-224-in21k\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(example_batch):\n",
    "  inputs = image_processor([x for x in example_batch[\"image\"]], return_tensors=\"pt\")\n",
    "  inputs[\"labels\"] = example_batch[\"labels\"]\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_ds = image_dataset.with_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "  return {\n",
    "      \"pixel_values\": torch.stack([x[\"pixel_values\"] for x in batch]),\n",
    "      \"labels\": torch.tensor([x[\"labels\"] for x in batch])\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g_/0lqz2qlx7cx96d901w35swh40000gn/T/ipykernel_55878/995733927.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(prediction):\n",
    "  return metric.compute(\n",
    "    predictions=np.argmax(prediction.predictions, axis=1), \n",
    "    references=prediction.label_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=2,\n",
    "    # id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    # label2id={c: str(i) for i,c in enumerate(labels)}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./image_model\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=2e-4,\n",
    "    load_best_model_at_end=True,\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': Image(decode=True, id=None),\n",
       " 'labels': Value(dtype='int64', id=None),\n",
       " '__index_level_0__': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_ds[\"train\"],\n",
    "    eval_dataset=prepared_ds[\"test\"],\n",
    "    tokenizer=image_processor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 500/14832 [16:18<6:40:03,  1.67s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6897, 'learning_rate': 0.00019325782092772384, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|â–Ž         | 500/14832 [26:58<6:40:03,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6864238977432251, 'eval_accuracy': 0.5611598111935266, 'eval_runtime': 639.9837, 'eval_samples_per_second': 11.586, 'eval_steps_per_second': 1.448, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 1000/14832 [43:24<7:05:12,  1.84s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6896, 'learning_rate': 0.0001865156418554477, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  7%|â–‹         | 1000/14832 [51:56<7:05:12,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.679474413394928, 'eval_accuracy': 0.5832771409305462, 'eval_runtime': 511.8828, 'eval_samples_per_second': 14.486, 'eval_steps_per_second': 1.811, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 1500/14832 [1:07:56<8:19:58,  2.25s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6926, 'learning_rate': 0.00017977346278317153, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 10%|â–ˆ         | 1500/14832 [1:16:27<8:19:58,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6855337619781494, 'eval_accuracy': 0.5595414699932569, 'eval_runtime': 510.8248, 'eval_samples_per_second': 14.516, 'eval_steps_per_second': 1.815, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 2000/14832 [1:32:21<6:34:51,  1.85s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6886, 'learning_rate': 0.00017303128371089536, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 13%|â–ˆâ–Ž        | 2000/14832 [1:41:13<6:34:51,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6853688955307007, 'eval_accuracy': 0.5611598111935266, 'eval_runtime': 531.867, 'eval_samples_per_second': 13.941, 'eval_steps_per_second': 1.743, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 2500/14832 [1:57:03<6:23:24,  1.87s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6876, 'learning_rate': 0.00016628910463861921, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 17%|â–ˆâ–‹        | 2500/14832 [2:05:35<6:23:24,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6869639754295349, 'eval_accuracy': 0.5611598111935266, 'eval_runtime': 512.657, 'eval_samples_per_second': 14.464, 'eval_steps_per_second': 1.808, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 3000/14832 [2:21:42<5:54:53,  1.80s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6872, 'learning_rate': 0.00015954692556634304, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 20%|â–ˆâ–ˆ        | 3000/14832 [2:30:19<5:54:53,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6846593618392944, 'eval_accuracy': 0.5614295347269049, 'eval_runtime': 516.518, 'eval_samples_per_second': 14.356, 'eval_steps_per_second': 1.795, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–Ž       | 3500/14832 [2:46:23<6:06:12,  1.94s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6871, 'learning_rate': 0.00015280474649406687, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 24%|â–ˆâ–ˆâ–Ž       | 3500/14832 [2:54:55<6:06:12,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6835988163948059, 'eval_accuracy': 0.5611598111935266, 'eval_runtime': 512.2217, 'eval_samples_per_second': 14.476, 'eval_steps_per_second': 1.81, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 4000/14832 [3:10:56<5:51:32,  1.95s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6868, 'learning_rate': 0.00014606256742179073, 'epoch': 1.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 27%|â–ˆâ–ˆâ–‹       | 4000/14832 [3:19:22<5:51:32,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6839420795440674, 'eval_accuracy': 0.5616992582602832, 'eval_runtime': 506.1689, 'eval_samples_per_second': 14.649, 'eval_steps_per_second': 1.831, 'epoch': 1.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 4500/14832 [3:35:03<5:08:33,  1.79s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6842, 'learning_rate': 0.00013932038834951456, 'epoch': 1.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 4500/14832 [3:43:29<5:08:33,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7286498546600342, 'eval_accuracy': 0.4426163182737694, 'eval_runtime': 506.5578, 'eval_samples_per_second': 14.638, 'eval_steps_per_second': 1.83, 'epoch': 1.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 5000/14832 [3:59:17<4:47:41,  1.76s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6885, 'learning_rate': 0.00013257820927723842, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 5000/14832 [4:07:43<4:47:41,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6806064248085022, 'eval_accuracy': 0.584086311530681, 'eval_runtime': 505.9861, 'eval_samples_per_second': 14.655, 'eval_steps_per_second': 1.832, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 5500/14832 [4:23:11<4:51:35,  1.87s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6858, 'learning_rate': 0.00012583603020496225, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 5500/14832 [4:31:35<4:51:35,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6828432679176331, 'eval_accuracy': 0.5616992582602832, 'eval_runtime': 503.706, 'eval_samples_per_second': 14.721, 'eval_steps_per_second': 1.84, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6000/14832 [4:47:21<4:31:40,  1.85s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6843, 'learning_rate': 0.00011909385113268609, 'epoch': 1.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6000/14832 [4:55:51<4:31:40,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6802411675453186, 'eval_accuracy': 0.5811193526635199, 'eval_runtime': 509.8615, 'eval_samples_per_second': 14.543, 'eval_steps_per_second': 1.818, 'epoch': 1.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 6500/14832 [5:11:41<4:14:45,  1.83s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6805, 'learning_rate': 0.00011235167206040992, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 6500/14832 [5:20:03<4:14:45,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6830241680145264, 'eval_accuracy': 0.5700606877950101, 'eval_runtime': 501.5634, 'eval_samples_per_second': 14.784, 'eval_steps_per_second': 1.848, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7000/14832 [5:35:37<3:55:19,  1.80s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6782, 'learning_rate': 0.00010560949298813377, 'epoch': 1.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7000/14832 [5:44:06<3:55:19,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6787985563278198, 'eval_accuracy': 0.5807147673634525, 'eval_runtime': 509.1635, 'eval_samples_per_second': 14.563, 'eval_steps_per_second': 1.821, 'epoch': 1.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 7500/14832 [5:59:57<3:46:34,  1.85s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6783, 'learning_rate': 9.886731391585761e-05, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 7500/14832 [6:08:34<3:46:34,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6831994652748108, 'eval_accuracy': 0.5761294672960215, 'eval_runtime': 516.7385, 'eval_samples_per_second': 14.35, 'eval_steps_per_second': 1.794, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 8000/14832 [6:23:49<3:25:21,  1.80s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6862, 'learning_rate': 9.212513484358145e-05, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 8000/14832 [6:32:11<3:25:21,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6789869666099548, 'eval_accuracy': 0.5838165879973027, 'eval_runtime': 501.5732, 'eval_samples_per_second': 14.783, 'eval_steps_per_second': 1.848, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 8500/14832 [6:47:30<3:08:23,  1.79s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6841, 'learning_rate': 8.53829557713053e-05, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 8500/14832 [6:55:52<3:08:23,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6784464716911316, 'eval_accuracy': 0.5890761968981794, 'eval_runtime': 502.2036, 'eval_samples_per_second': 14.765, 'eval_steps_per_second': 1.846, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9000/14832 [7:13:15<3:17:31,  2.03s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6761, 'learning_rate': 7.864077669902913e-05, 'epoch': 2.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9000/14832 [7:22:00<3:17:31,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6748365759849548, 'eval_accuracy': 0.596223870532704, 'eval_runtime': 524.6276, 'eval_samples_per_second': 14.134, 'eval_steps_per_second': 1.767, 'epoch': 2.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9500/14832 [7:37:47<3:00:24,  2.03s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6757, 'learning_rate': 7.189859762675297e-05, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9500/14832 [7:46:06<3:00:24,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6769204139709473, 'eval_accuracy': 0.5885367498314228, 'eval_runtime': 499.3299, 'eval_samples_per_second': 14.85, 'eval_steps_per_second': 1.856, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10000/14832 [8:01:35<2:32:00,  1.89s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6751, 'learning_rate': 6.51564185544768e-05, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10000/14832 [8:10:00<2:32:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6756672859191895, 'eval_accuracy': 0.5913688469318948, 'eval_runtime': 504.9822, 'eval_samples_per_second': 14.684, 'eval_steps_per_second': 1.836, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 10500/14832 [8:25:37<2:10:26,  1.81s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6777, 'learning_rate': 5.841423948220065e-05, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 10500/14832 [8:33:55<2:10:26,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6729500889778137, 'eval_accuracy': 0.5939312204989885, 'eval_runtime': 497.8827, 'eval_samples_per_second': 14.893, 'eval_steps_per_second': 1.862, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 11000/14832 [8:49:17<1:57:49,  1.84s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6712, 'learning_rate': 5.1672060409924495e-05, 'epoch': 2.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 11000/14832 [8:57:48<1:57:49,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6710619330406189, 'eval_accuracy': 0.5975724881995954, 'eval_runtime': 511.6107, 'eval_samples_per_second': 14.493, 'eval_steps_per_second': 1.812, 'epoch': 2.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 11500/14832 [9:13:27<1:36:50,  1.74s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6762, 'learning_rate': 4.4929881337648325e-05, 'epoch': 3.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 11500/14832 [9:21:50<1:36:50,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6702340245246887, 'eval_accuracy': 0.6006743088334457, 'eval_runtime': 502.8142, 'eval_samples_per_second': 14.747, 'eval_steps_per_second': 1.844, 'epoch': 3.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12000/14832 [9:37:26<1:56:01,  2.46s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6664, 'learning_rate': 3.818770226537217e-05, 'epoch': 3.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12000/14832 [9:45:49<1:56:01,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6701256036758423, 'eval_accuracy': 0.5968981793661498, 'eval_runtime': 502.9959, 'eval_samples_per_second': 14.742, 'eval_steps_per_second': 1.843, 'epoch': 3.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 12500/14832 [10:01:26<1:09:04,  1.78s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.672, 'learning_rate': 3.144552319309601e-05, 'epoch': 3.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 12500/14832 [10:10:03<1:09:04,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6699047684669495, 'eval_accuracy': 0.5978422117329737, 'eval_runtime': 516.6017, 'eval_samples_per_second': 14.353, 'eval_steps_per_second': 1.794, 'epoch': 3.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 13000/14832 [10:26:04<54:43,  1.79s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6693, 'learning_rate': 2.470334412081985e-05, 'epoch': 3.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 13000/14832 [10:34:33<54:43,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6685929894447327, 'eval_accuracy': 0.5995954146999326, 'eval_runtime': 508.9621, 'eval_samples_per_second': 14.569, 'eval_steps_per_second': 1.821, 'epoch': 3.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 13500/14832 [10:50:27<40:22,  1.82s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6628, 'learning_rate': 1.796116504854369e-05, 'epoch': 3.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 13500/14832 [10:59:00<40:22,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6754112839698792, 'eval_accuracy': 0.5937963587322994, 'eval_runtime': 513.4522, 'eval_samples_per_second': 14.441, 'eval_steps_per_second': 1.805, 'epoch': 3.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 14000/14832 [11:14:52<24:38,  1.78s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6677, 'learning_rate': 1.121898597626753e-05, 'epoch': 3.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 14000/14832 [11:23:19<24:38,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6673158407211304, 'eval_accuracy': 0.597167902899528, 'eval_runtime': 507.1392, 'eval_samples_per_second': 14.621, 'eval_steps_per_second': 1.828, 'epoch': 3.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 14500/14832 [11:38:51<09:57,  1.80s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6639, 'learning_rate': 4.47680690399137e-06, 'epoch': 3.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 14500/14832 [11:47:10<09:57,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6658162474632263, 'eval_accuracy': 0.6006743088334457, 'eval_runtime': 499.1411, 'eval_samples_per_second': 14.856, 'eval_steps_per_second': 1.857, 'epoch': 3.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14832/14832 [11:57:30<00:00,  2.90s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 43050.8307, 'train_samples_per_second': 2.756, 'train_steps_per_second': 0.345, 'train_loss': 0.6794167398249061, 'epoch': 4.0}\n",
      "***** train metrics *****\n",
      "  epoch                    =         4.0\n",
      "  train_loss               =      0.6794\n",
      "  train_runtime            = 11:57:30.83\n",
      "  train_samples_per_second =       2.756\n",
      "  train_steps_per_second   =       0.345\n"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 927/927 [09:26<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        4.0\n",
      "  eval_accuracy           =     0.6007\n",
      "  eval_loss               =     0.6658\n",
      "  eval_runtime            = 0:09:33.07\n",
      "  eval_samples_per_second =     12.939\n",
      "  eval_steps_per_second   =      1.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(prepared_ds[\"test\"])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake_news-6ZUGHfY-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
